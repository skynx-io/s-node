package metricsdb

import (
	"fmt"
	"time"

	"skynx.io/s-api-go/grpc/resources/nstore"
	"skynx.io/s-api-go/grpc/resources/nstore/metricsdb"
	"skynx.io/s-lib/pkg/errors"
	"skynx.io/s-lib/pkg/xlog"
)

type aggTask struct {
	srcTimeRange nstore.TimeRange
	aggInterval  time.Duration
	jobInterval  time.Duration
}

var aggTaskMap map[nstore.TimeRange]*aggTask = map[nstore.TimeRange]*aggTask{
	nstore.TimeRange_TTL_6H: {
		srcTimeRange: nstore.TimeRange_TTL_1H,
		aggInterval:  12 * time.Minute,
		jobInterval:  12*time.Minute + (10 * time.Second),
	},
	nstore.TimeRange_TTL_12H: {
		srcTimeRange: nstore.TimeRange_TTL_1H,
		aggInterval:  24 * time.Minute,
		jobInterval:  24*time.Minute + (22 * time.Second),
	},
	nstore.TimeRange_TTL_24H: {
		srcTimeRange: nstore.TimeRange_TTL_6H,
		aggInterval:  48 * time.Minute,
		jobInterval:  48*time.Minute + (33 * time.Second),
	},
	nstore.TimeRange_TTL_7D: {
		srcTimeRange: nstore.TimeRange_TTL_12H,
		aggInterval:  336 * time.Minute,
		jobInterval:  336*time.Minute + (45 * time.Second),
	},
	nstore.TimeRange_TTL_14D: {
		srcTimeRange: nstore.TimeRange_TTL_24H,
		aggInterval:  672 * time.Minute,
		jobInterval:  672*time.Minute + (57 * time.Second),
	},
	nstore.TimeRange_TTL_30D: {
		srcTimeRange: nstore.TimeRange_TTL_7D,
		aggInterval:  1344 * time.Minute,
		jobInterval:  1344*time.Minute + (71 * time.Second),
	},
	nstore.TimeRange_TTL_365D: {
		srcTimeRange: nstore.TimeRange_TTL_30D,
		aggInterval:  12 * 24 * time.Hour,
		jobInterval:  12*24*time.Hour + (87 * time.Second),
	},
}

func (tsdb *tsDB) aggController() {
	ticker6H := time.NewTicker(aggTaskMap[nstore.TimeRange_TTL_6H].jobInterval)
	defer ticker6H.Stop()
	ticker12H := time.NewTicker(aggTaskMap[nstore.TimeRange_TTL_12H].jobInterval)
	defer ticker12H.Stop()
	ticker24H := time.NewTicker(aggTaskMap[nstore.TimeRange_TTL_24H].jobInterval)
	defer ticker24H.Stop()
	ticker7D := time.NewTicker(aggTaskMap[nstore.TimeRange_TTL_7D].jobInterval)
	defer ticker7D.Stop()
	ticker14D := time.NewTicker(aggTaskMap[nstore.TimeRange_TTL_14D].jobInterval)
	defer ticker14D.Stop()
	ticker30D := time.NewTicker(aggTaskMap[nstore.TimeRange_TTL_30D].jobInterval)
	defer ticker30D.Stop()
	ticker365D := time.NewTicker(aggTaskMap[nstore.TimeRange_TTL_365D].jobInterval)
	defer ticker365D.Stop()

	for {
		select {
		case <-ticker6H.C:
			dstTimeRange := nstore.TimeRange_TTL_6H
			if err := tsdb.runAggregation(dstTimeRange); err != nil {
				xlog.Errorf("[metricsdb] Unable to complete aggregation job %s: %v",
					dstTimeRange.String(), err)
			}
			xlog.Debugf("[metricsdb] Aggregation job %s completed", dstTimeRange.String())

		case <-ticker12H.C:
			dstTimeRange := nstore.TimeRange_TTL_12H
			if err := tsdb.runAggregation(dstTimeRange); err != nil {
				xlog.Errorf("[metricsdb] Unable to complete aggregation job %s: %v",
					dstTimeRange.String(), err)
			}
			xlog.Debugf("[metricsdb] Aggregation job %s completed", dstTimeRange.String())

		case <-ticker24H.C:
			dstTimeRange := nstore.TimeRange_TTL_24H
			if err := tsdb.runAggregation(dstTimeRange); err != nil {
				xlog.Errorf("[metricsdb] Unable to complete aggregation job %s: %v",
					dstTimeRange.String(), err)
			}
			xlog.Debugf("[metricsdb] Aggregation job %s completed", dstTimeRange.String())

		case <-ticker7D.C:
			dstTimeRange := nstore.TimeRange_TTL_7D
			if err := tsdb.runAggregation(dstTimeRange); err != nil {
				xlog.Errorf("[metricsdb] Unable to complete aggregation job %s: %v",
					dstTimeRange.String(), err)
			}
			xlog.Debugf("[metricsdb] Aggregation job %s completed", dstTimeRange.String())

		case <-ticker14D.C:
			dstTimeRange := nstore.TimeRange_TTL_14D
			if err := tsdb.runAggregation(dstTimeRange); err != nil {
				xlog.Errorf("[metricsdb] Unable to complete aggregation job %s: %v",
					dstTimeRange.String(), err)
			}
			xlog.Debugf("[metricsdb] Aggregation job %s completed", dstTimeRange.String())

		case <-ticker30D.C:
			dstTimeRange := nstore.TimeRange_TTL_30D
			if err := tsdb.runAggregation(dstTimeRange); err != nil {
				xlog.Errorf("[metricsdb] Unable to complete aggregation job %s: %v",
					dstTimeRange.String(), err)
			}
			xlog.Debugf("[metricsdb] Aggregation job %s completed", dstTimeRange.String())

		case <-ticker365D.C:
			dstTimeRange := nstore.TimeRange_TTL_365D
			if err := tsdb.runAggregation(dstTimeRange); err != nil {
				xlog.Errorf("[metricsdb] Unable to complete aggregation job %s: %v",
					dstTimeRange.String(), err)
			}
			xlog.Debugf("[metricsdb] Aggregation job %s completed", dstTimeRange.String())

		case <-tsdb.aggControllerCloseCh:
			return
		}
	}
}

type aggDataPoint struct {
	tmStart  time.Time
	tmStop   time.Time
	metric   metricsdb.HostMetricType
	valueSum float64
	numKeys  int
}

func (tsdb *tsDB) runAggregation(dstTimeRange nstore.TimeRange) error {
	srcTimeRange := aggTaskMap[dstTimeRange].srcTimeRange
	aggInterval := aggTaskMap[dstTimeRange].aggInterval

	srcKeyPrefix := []byte(fmt.Sprintf("%d:", int(srcTimeRange)))
	dstKeyPrefix := []byte(fmt.Sprintf("%d:", int(dstTimeRange)))

	dpLast, err := tsdb.Last(dstKeyPrefix)
	if err != nil {
		return errors.Wrapf(err, "[%v] function tsdb.Last()", errors.Trace())
	}

	dps, err := tsdb.Scan(srcKeyPrefix)
	if err != nil {
		return errors.Wrapf(err, "[%v] function tsdb.Scan()", errors.Trace())
	}

	adpList := make([]*metricsdb.HostMetricDataPoint, 0)
	adpMap := make(map[metricsdb.HostMetricType]*aggDataPoint)

	for _, dp := range dps {
		tm := time.UnixMilli(dp.Timestamp)

		if time.Since(tm) < aggInterval {
			continue
		}

		if dpLast != nil {
			tmLast := time.UnixMilli(dpLast.Timestamp)
			if tm.Before(tmLast) {
				continue
			}
		}

		adp, ok := adpMap[dp.Metric]
		if ok {
			if tm.After(adp.tmStart) && tm.Before(adp.tmStop) {
				adp.valueSum += dp.Value
				adp.numKeys++
			} else {
				if tm.After(adp.tmStop) {
					adpList = append(adpList, &metricsdb.HostMetricDataPoint{
						Timestamp: adp.tmStop.UnixMilli(),
						TimeRange: dstTimeRange,
						Metric:    adp.metric,
						Value:     adp.valueSum / float64(adp.numKeys),
					})
					adpMap[dp.Metric] = newAggDataPoint(dp, aggInterval)
				}
			}
		} else {
			adpMap[dp.Metric] = newAggDataPoint(dp, aggInterval)
		}
	}

	if err := tsdb.WriteBatch(adpList); err != nil {
		return errors.Wrapf(err, "[%v] function tsdb.WriteBatch()", errors.Trace())
	}

	return nil
}

func newAggDataPoint(dp *metricsdb.HostMetricDataPoint, aggInterval time.Duration) *aggDataPoint {
	adp := &aggDataPoint{
		metric:   dp.Metric,
		valueSum: dp.Value,
		numKeys:  1,
	}
	tmStart := time.UnixMilli(dp.Timestamp)
	tmStop := tmStart.Add(aggInterval)
	adp.tmStart = tmStart
	adp.tmStop = tmStop

	return adp
}
